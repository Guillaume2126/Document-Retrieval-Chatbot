{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pypdfium2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Application.data_cleaning import process_pdfs_and_build_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code was to split each 100s PDFs into excel files with two columns:\n",
    "# Name of the document and clean text\n",
    "\"\"\"\n",
    "from Application.data_cleaning import process_pdfs_and_build_dataframe\n",
    "pdf_directory =\"../Data/Data/PDFs\"\n",
    "document_texts_900_998 = process_pdfs_and_build_dataframe(pdf_directory, 900, 998)\n",
    "document_texts_900_998.to_excel(\"../Data/output_batch_900_998.xlsx\", index=False)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code was used to merge every excel files into a big one\n",
    "\"\"\"import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create a list for each excel files\n",
    "all_batches = []\n",
    "\n",
    "excel_directory = \"/home/guillaumelewagon/code/Guillaume2126/Document-Retrieval-Chatbot/Data/\"\n",
    "\n",
    "for batch_number in range(1, 11):\n",
    "    file_name = f\"{(batch_number - 1) * 100 + 1}_{batch_number * 100}\"\n",
    "\n",
    "    excel_filename = f\"output_batch_{file_name}.xlsx\"\n",
    "    excel_path = os.path.join(excel_directory, excel_filename)\n",
    "\n",
    "    df_batch = pd.read_excel(excel_path)\n",
    "    all_batches.append(df_batch)\n",
    "\n",
    "all_document_texts = pd.concat(all_batches, ignore_index=True)\n",
    "\n",
    "output_file_path = os.path.join(excel_directory, \"output_all_batches.xlsx\")\n",
    "all_document_texts.to_excel(output_file_path, index=False)\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from Application.data_cleaning import cleaning\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "data_path = \"../Data/\"\n",
    "df = pd.read_excel(os.path.join(data_path, \"output_all_batches.xlsx\"))\n",
    "df[\"Clean text\"].fillna(\"\", inplace=True)\n",
    "\n",
    "# Vectorize text\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df[\"Clean text\"])\n",
    "\n",
    "# Save the TfidfVectorizer\n",
    "vectorizer_path = \"../Application/tfidf_vectorizer.joblib\"\n",
    "joblib.dump(tfidf_vectorizer, vectorizer_path)\n",
    "\n",
    "# Save the matrix TF-IDF\n",
    "matrix_path = \"../Application/tfidf_matrix.joblib\"\n",
    "joblib.dump(tfidf_matrix, matrix_path)\n",
    "\n",
    "# Function to find the document similar to the request\n",
    "def get_most_similar_documents(query, tfidf_matrix, tfidf_vectorizer, top_n=5):\n",
    "    # Clean and vectorize the request\n",
    "    query = cleaning(query)\n",
    "    query_vector = tfidf_vectorizer.transform([query])\n",
    "\n",
    "    # Calculate the similarity between the request and all the documents\n",
    "    cosine_similarities = linear_kernel(query_vector, tfidf_matrix).flatten()\n",
    "\n",
    "    # Sort by similarity\n",
    "    document_indices = cosine_similarities.argsort()[:-top_n-1:-1]\n",
    "\n",
    "    # Create a DataFrame with the results\n",
    "    result_df = df.iloc[document_indices].copy()\n",
    "\n",
    "    # Add a column for similarity scores\n",
    "    result_df[\"Similarity Score\"] = cosine_similarities[document_indices]\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents corresponding to the request :\n",
      "    Name of the document                                         Clean text  \\\n",
      "852     30_wall_oven.pdf  ge monogram use care guide wall oven downloade...   \n",
      "949        139900300.pdf  use care wwwfrigidairecom usa wwwfrigidaireca ...   \n",
      "149      30_b3007hlb.pdf  user manual bhlb builtin oven user manual down...   \n",
      "419        316417012.pdf  pn rev c range e control selfcleaning oven cer...   \n",
      "141           msh28b.pdf  model mshb electric mini oven hob please read ...   \n",
      "\n",
      "     Similarity Score  \n",
      "852          0.701334  \n",
      "949          0.693870  \n",
      "149          0.663768  \n",
      "419          0.619903  \n",
      "141          0.605817  \n"
     ]
    }
   ],
   "source": [
    "user_query = \"How to use an electric oven :\"\n",
    "similar_documents = get_most_similar_documents(user_query, tfidf_matrix, tfidf_vectorizer)\n",
    "\n",
    "print(\"Documents corresponding to the request :\")\n",
    "print(similar_documents[[\"Name of the document\", \"Clean text\", \"Similarity Score\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other models or methods could be used like Word2Vec, Doc2Vec or BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
