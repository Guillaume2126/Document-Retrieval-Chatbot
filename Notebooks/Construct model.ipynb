{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/ce/3f/1dafc52526337d1c554227b0e6f16a1aee18e63bf5cd03fd7774297059b2/langchain-0.0.338-py3-none-any.whl.metadata\n",
      "  Using cached langchain-0.0.338-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/guillaumelewagon/.pyenv/versions/3.10.6/envs/lewagon_current/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Obtaining dependency information for SQLAlchemy<3,>=1.4 from https://files.pythonhosted.org/packages/aa/1c/0b66318368b1c9ef51c5c8560530b8ef842164e10eea08cacb06739388e0/SQLAlchemy-2.0.23-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached SQLAlchemy-2.0.23-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Obtaining dependency information for aiohttp<4.0.0,>=3.8.3 from https://files.pythonhosted.org/packages/b0/36/c7bd200871e7351ab8396e8edcbb91e1198e0ded67a0824c93110c4c5df2/aiohttp-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached aiohttp-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: anyio<4.0 in /home/guillaumelewagon/.pyenv/versions/3.10.6/envs/lewagon_current/lib/python3.10/site-packages (from langchain) (3.7.1)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Obtaining dependency information for async-timeout<5.0.0,>=4.0.0 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Obtaining dependency information for dataclasses-json<0.7,>=0.5.7 from https://files.pythonhosted.org/packages/8d/e2/528c52001a743a7faa28e6d3095d9f01b472d3efee62d62101403bf1a70a/dataclasses_json-0.6.2-py3-none-any.whl.metadata\n",
      "  Using cached dataclasses_json-0.6.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
      "  Obtaining dependency information for langsmith<0.1.0,>=0.0.63 from https://files.pythonhosted.org/packages/a0/d4/79038c47526f84ad9b6ec2a27b46e8e97897e70cd0579c9a6dbcf1d2adea/langsmith-0.0.65-py3-none-any.whl.metadata\n",
      "  Using cached langsmith-0.0.65-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/guillaumelewagon/.pyenv/versions/3.10.6/envs/lewagon_current/lib/python3.10/site-packages (from langchain) (1.23.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/guillaumelewagon/.pyenv/versions/3.10.6/envs/lewagon_current/lib/python3.10/site-packages (from langchain) (1.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/guillaumelewagon/.pyenv/versions/3.10.6/envs/lewagon_current/lib/python3.10/site-packages (from langchain) (2.28.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/guillaumelewagon/.pyenv/versions/3.10.6/envs/lewagon_current/lib/python3.10/site-packages (from langchain) (8.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/guillaumelewagon/.pyenv/versions/3.10.6/envs/lewagon_current/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/1e/28/74b8b6451c89c070d34e753d8b65a1e4ce508a6808b18529f36e8c0e2184/frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /home/guillaumelewagon/.pyenv/versions/3.10.6/envs/lewagon_current/lib/python3.10/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/guillaumelewagon/.pyenv/versions/3.10.6/envs/lewagon_current/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/guillaumelewagon/.pyenv/versions/3.10.6/envs/lewagon_current/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.1.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/ed/3c/cebfdcad015240014ff08b883d1c0c427f2ba45ae8c6572851b6ef136cad/marshmallow-3.20.1-py3-none-any.whl.metadata\n",
      "  Using cached marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Obtaining dependency information for jsonpointer>=1.9 from https://files.pythonhosted.org/packages/12/f6/0232cc0c617e195f06f810534d00b74d2f348fe71b2118009ad8ad31f878/jsonpointer-2.4-py2.py3-none-any.whl.metadata\n",
      "  Using cached jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/guillaumelewagon/.pyenv/versions/3.10.6/envs/lewagon_current/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/guillaumelewagon/.pyenv/versions/3.10.6/envs/lewagon_current/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/guillaumelewagon/.pyenv/versions/3.10.6/envs/lewagon_current/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/guillaumelewagon/.pyenv/versions/3.10.6/envs/lewagon_current/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2022.9.24)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Obtaining dependency information for greenlet!=0.4.17 from https://files.pythonhosted.org/packages/da/ab/7cc6502628565d70dce2edb619d87554d65ac4e2f17c805a5a45bfaefa5c/greenlet-3.0.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata\n",
      "  Using cached greenlet-3.0.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/guillaumelewagon/.pyenv/versions/3.10.6/envs/lewagon_current/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (21.3)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/guillaumelewagon/.pyenv/versions/3.10.6/envs/lewagon_current/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (3.0.9)\n",
      "Using cached langchain-0.0.338-py3-none-any.whl (2.0 MB)\n",
      "Using cached aiohttp-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached dataclasses_json-0.6.2-py3-none-any.whl (28 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langsmith-0.0.65-py3-none-any.whl (46 kB)\n",
      "Using cached SQLAlchemy-2.0.23-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
      "Using cached greenlet-3.0.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (613 kB)\n",
      "Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Using cached marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: mypy-extensions, multidict, jsonpointer, greenlet, frozenlist, async-timeout, yarl, typing-inspect, SQLAlchemy, marshmallow, langsmith, jsonpatch, aiosignal, dataclasses-json, aiohttp, langchain\n",
      "Successfully installed SQLAlchemy-2.0.23 aiohttp-3.9.0 aiosignal-1.3.1 async-timeout-4.0.3 dataclasses-json-0.6.2 frozenlist-1.4.0 greenlet-3.0.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.338 langsmith-0.0.65 marshmallow-3.20.1 multidict-6.0.4 mypy-extensions-1.0.0 typing-inspect-0.9.0 yarl-1.9.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdfium2\n",
      "  Obtaining dependency information for pypdfium2 from https://files.pythonhosted.org/packages/64/a1/8e9f4c5ace3bc19cd6d9d0dedbfae0bc01e701e861e4de4e1a7f8bdf0533/pypdfium2-4.24.0-py3-none-manylinux_2_17_x86_64.whl.metadata\n",
      "  Using cached pypdfium2-4.24.0-py3-none-manylinux_2_17_x86_64.whl.metadata (45 kB)\n",
      "Using cached pypdfium2-4.24.0-py3-none-manylinux_2_17_x86_64.whl (3.0 MB)\n",
      "Installing collected packages: pypdfium2\n",
      "Successfully installed pypdfium2-4.24.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pypdfium2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "import sys\n",
    "sys.path.append('/home/guillaumelewagon/code/Guillaume2126/Document-Retrieval-Chatbot')\n",
    "from Application.data_cleaning import process_pdfs_and_build_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 901\n",
      "Document 902\n",
      "Document 903\n",
      "Document 904\n",
      "Document 905\n",
      "Document 906\n",
      "Document 907\n",
      "Document 908\n",
      "Document 909\n",
      "Document 910\n",
      "Document 911\n",
      "Document 912\n",
      "Document 913\n",
      "Document 914\n",
      "Document 915\n",
      "Document 916\n",
      "Document 917\n",
      "Document 918\n",
      "Document 919\n",
      "Document 920\n",
      "Document 921\n",
      "Document 922\n",
      "Document 923\n",
      "Document 924\n",
      "Document 925\n",
      "Document 926\n",
      "Document 927\n",
      "Document 928\n",
      "Document 929\n",
      "Document 930\n",
      "Document 931\n",
      "Document 932\n",
      "Document 933\n",
      "Document 934\n",
      "Document 935\n",
      "Document 936\n",
      "Document 937\n",
      "Document 938\n",
      "Document 939\n",
      "Document 940\n",
      "Document 941\n",
      "Document 942\n",
      "Document 943\n",
      "Document 944\n",
      "Document 945\n",
      "Document 946\n",
      "Document 947\n",
      "Document 948\n",
      "Document 949\n",
      "Document 950\n",
      "Document 951\n",
      "Document 952\n",
      "Document 953\n",
      "Document 954\n",
      "Document 955\n",
      "Document 956\n",
      "Document 957\n",
      "Document 958\n",
      "Document 959\n",
      "Document 960\n",
      "Document 961\n",
      "Document 962\n",
      "Document 963\n",
      "Document 964\n",
      "Document 965\n",
      "Document 966\n",
      "Document 967\n",
      "Document 968\n",
      "Document 969\n",
      "Document 970\n",
      "Document 971\n",
      "Document 972\n",
      "Document 973\n",
      "Document 974\n",
      "Document 975\n",
      "Document 976\n",
      "Document 977\n",
      "Document 978\n",
      "Document 979\n",
      "Document 980\n",
      "Document 981\n",
      "Document 982\n",
      "Document 983\n",
      "Document 984\n",
      "Document 985\n",
      "Document 986\n",
      "Document 987\n",
      "Document 988\n",
      "Document 989\n",
      "Document 990\n",
      "Document 991\n",
      "Document 992\n",
      "Document 993\n",
      "Document 994\n",
      "Document 995\n",
      "Document 996\n",
      "Document 997\n"
     ]
    }
   ],
   "source": [
    "# This code was to split each 100s PDFs into excel files with two columns: Name of the document and clean text\n",
    "\"\"\"pdf_directory =\"/home/guillaumelewagon/code/Guillaume2126/Document-Retrieval-Chatbot/Data/Data/PDFs\"\n",
    "document_texts_900_998 = process_pdfs_and_build_dataframe(pdf_directory, 900, 998)\n",
    "document_texts_900_998.to_excel(\"/home/guillaumelewagon/code/Guillaume2126/Document-Retrieval-Chatbot/Data/output_batch_900_998.xlsx\", index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create a list for each excel files\n",
    "all_batches = []\n",
    "\n",
    "excel_directory = \"/home/guillaumelewagon/code/Guillaume2126/Document-Retrieval-Chatbot/Data/\"\n",
    "\n",
    "for batch_number in range(1, 11):\n",
    "    file_name = f\"{(batch_number - 1) * 100 + 1}_{batch_number * 100}\"\n",
    "\n",
    "    excel_filename = f\"output_batch_{file_name}.xlsx\"\n",
    "    excel_path = os.path.join(excel_directory, excel_filename)\n",
    "\n",
    "    df_batch = pd.read_excel(excel_path)\n",
    "    all_batches.append(df_batch)\n",
    "\n",
    "all_document_texts = pd.concat(all_batches, ignore_index=True)\n",
    "\n",
    "output_file_path = os.path.join(excel_directory, \"output_all_batches.xlsx\")\n",
    "all_document_texts.to_excel(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- First model -Kind of baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from Application.data_cleaning import cleaning\n",
    "\n",
    "data_path = \"/home/guillaumelewagon/code/Guillaume2126/Document-Retrieval-Chatbot/Data/\"\n",
    "df = pd.read_excel(os.path.join(data_path, \"output_all_batches.xlsx\"))\n",
    "df[\"Clean text\"].fillna(\"\", inplace=True)\n",
    "\n",
    "# Vectorize text\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df[\"Clean text\"])\n",
    "\n",
    "# Function to find the document similar to the request\n",
    "def get_most_similar_documents(query, tfidf_matrix, tfidf_vectorizer, top_n=5):\n",
    "    # Clean and vectorize the request\n",
    "    query = cleaning(query)\n",
    "    query_vector = tfidf_vectorizer.transform([query])\n",
    "\n",
    "    # Calculate the similarity between the request and all the documents\n",
    "    cosine_similarities = linear_kernel(query_vector, tfidf_matrix).flatten()\n",
    "\n",
    "    # Sort by similarity\n",
    "    document_indices = cosine_similarities.argsort()[:-top_n-1:-1]\n",
    "\n",
    "    # Create a DataFrame with the results\n",
    "    result_df = all_document_texts.iloc[document_indices].copy()\n",
    "\n",
    "    # Add a column for similarity scores\n",
    "    result_df[\"Similarity Score\"] = cosine_similarities[document_indices]\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents corresponding to the request :\n",
      "    Name of the document                                         Clean text  \\\n",
      "852     30_wall_oven.pdf  ge monogram use care guide wall oven downloade...   \n",
      "949        139900300.pdf  use care wwwfrigidairecom usa wwwfrigidaireca ...   \n",
      "149      30_b3007hlb.pdf  user manual bhlb builtin oven user manual down...   \n",
      "419        316417012.pdf  pn rev c range e control selfcleaning oven cer...   \n",
      "141           msh28b.pdf  model mshb electric mini oven hob please read ...   \n",
      "\n",
      "     Similarity Score  \n",
      "852          0.701334  \n",
      "949          0.693870  \n",
      "149          0.663768  \n",
      "419          0.619903  \n",
      "141          0.605817  \n"
     ]
    }
   ],
   "source": [
    "user_query = \"How to use an electric oven ?\"\n",
    "similar_documents = get_most_similar_documents(user_query, tfidf_matrix, tfidf_vectorizer)\n",
    "\n",
    "print(\"Documents corresponding to the request :\")\n",
    "print(similar_documents[[\"Name of the document\", \"Clean text\", \"Similarity Score\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Second model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See \n",
    "https://python.langchain.com/docs/modules/model_io/prompts/example_selectors/similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_texts_700_800 = process_pdfs_and_build_dataframe(pdf_directory, 700, 800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_texts_800_900 = process_pdfs_and_build_dataframe(pdf_directory, 800, 900)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_texts_900_1000 = process_pdfs_and_build_dataframe(pdf_directory, 900, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
